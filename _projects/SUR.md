---
layout: page
title: "Deep Recurrent Q-Learning for Partially Observable MDPs"
permalink: /projects/SUR/
---


  [_CS 726: Advanced Machine Learning_](https://www.cse.iitb.ac.in/~sunita/cs726/), [_Prof. Sunita Sarawagi_](hhttps://www.cse.iitb.ac.in/~sunita/) 

  <div style="display: flex;">
        <a href="/assets/pdf/Project.pdf" style="flex: 1; padding: 10px; border: 1px solid grey; text-align: center; text-decoration: none;">
        <div style="font-weight: bold; color: orchid;">Report</div>
    </a>
    <a href="/assets/pdf/Presentation.pdf" style="flex: 1; padding: 10px; border: 1px solid grey; text-align: center; text-decoration: none;">
        <div style="font-weight: bold; color: orchid;">Presentation</div>
    </a>
</div>

<br>

<p align="center">
    <img width="450"  src="/assets/img/.gif">
</p>

# Semantic Enhancement of text to Image Diffusion Models
In this project, we explored and experimented with advanced research papers focused on enhancing the semantic understanding of text-to-image generators. Specifically, we delved into:

<p align="center">
    <img width="450" src="/assets/img/DQN.png">
    <br>
    <em>Double Deep Q-Network</em>
</p>

	•	SUR-adapter: Enhancing Text-to-Image Pre-trained Diffusion Models with Large Language Models (LLMs)
	•	ELLA: Equipping Diffusion Models with LLMs for Enhanced Semantic Alignment

Our work involved devising architectural changes and modifications to these implementations, aiming to improve the semantic understanding of the stable diffusion pipeline. We meticulously compared our enhanced models with the vanilla implementations to evaluate performance improvements.
